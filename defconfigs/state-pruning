# SPDX-License-Identifier: MIT
# Test state-based pruning with AdamWPrune

# Enable multiple pruning mode
CONFIG_PRUNING_MODE_MULTIPLE=y

# General settings
CONFIG_BATCH_SIZE=512
CONFIG_NUM_EPOCHS=10
CONFIG_LEARNING_RATE="0.001"
CONFIG_NUM_WORKERS=16
CONFIG_DEVICE="cuda"
CONFIG_DATA_DIR="data"
CONFIG_OUTPUT_DIR="results"
CONFIG_JSON_OUTPUT="training_metrics.json"

# Models - test both LeNet-5 and ResNet-18
CONFIG_MODEL_MODE_MULTIPLE=y
CONFIG_MODEL_ENABLE_LENET5=y
CONFIG_MODEL_ENABLE_RESNET18=y
CONFIG_TEST_MODELS="lenet5,resnet18"
CONFIG_LENET5_NUM_CLASSES=10
CONFIG_LENET5_DATASET="mnist"
CONFIG_RESNET18_NUM_CLASSES=10
CONFIG_RESNET18_DATASET="cifar10"

# Use AdamWPrune optimizer (required for state-based pruning)
CONFIG_OPTIMIZER_MODE_SINGLE=y
CONFIG_OPTIMIZER_SELECT_ADAMWPRUNE=y

# Enable state-based pruning only
CONFIG_PRUNING_ENABLE_STATE=y

# Sparsity configuration - test multiple levels
CONFIG_SPARSITY_ENABLE_50=y
CONFIG_SPARSITY_ENABLE_70=y
CONFIG_SPARSITY_ENABLE_90=y

# Default state pruning settings
CONFIG_TARGET_SPARSITY="0.9"
CONFIG_PRUNING_WARMUP=100
CONFIG_PRUNING_FREQUENCY=50
CONFIG_PRUNING_RAMP_END_EPOCH=8
CONFIG_PRUNING_LOG_SPARSITY=y

# State-based pruning specific settings
CONFIG_STATE_PRUNING_STRATEGY="hybrid"
CONFIG_STATE_PRUNING_MOMENTUM_WEIGHT="0.5"

# Advanced features
CONFIG_COMPILE_MODEL=y
CONFIG_MIXED_PRECISION=y
CONFIG_GPU_WARMUP=y
CONFIG_PIN_MEMORY=y
CONFIG_PERSISTENT_WORKERS=y
CONFIG_PREFETCH_FACTOR=2
CONFIG_GRADIENT_CLIP_NORM="1.0"
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1

# Verbose output
CONFIG_VERBOSE=y
CONFIG_LOG_LEVEL="INFO"
CONFIG_DEBUG=n
CONFIG_PROFILE=n