# SPDX-License-Identifier: MIT
# GPT-2 Transformer Model Configuration

menu "GPT-2 Configuration"

choice
	prompt "GPT-2 Model Size"
	default GPT2_MODEL_124M
	help
	  Select the GPT-2 model size to use.
	  Larger models have better performance but require more memory.

config GPT2_MODEL_124M
	bool "GPT-2 124M (base) - RECOMMENDED"
	help
	  Base GPT-2 model with 124M parameters.
	  12 layers, 12 heads, 768 embedding dimension.
	  System RAM: 8-16 GB required for loading
	  GPU Memory: ~4-8 GB for training (batch size dependent)

config GPT2_MODEL_350M
	bool "GPT-2 350M (medium) - REQUIRES 32GB+ SYSTEM RAM"
	help
	  Medium GPT-2 model with 350M parameters.
	  24 layers, 16 heads, 1024 embedding dimension.
	  WARNING: Requires 32-64 GB system RAM for loading!
	  GPU Memory: ~8-16 GB for training

config GPT2_MODEL_774M
	bool "GPT-2 774M (large) - REQUIRES 64GB+ SYSTEM RAM"
	help
	  Large GPT-2 model with 774M parameters.
	  36 layers, 20 heads, 1280 embedding dimension.
	  WARNING: Requires 64-128 GB system RAM for loading!
	  GPU Memory: ~16-24 GB for training

config GPT2_MODEL_1558M
	bool "GPT-2 1.5B (xl) - REQUIRES 128GB+ SYSTEM RAM"
	help
	  Extra large GPT-2 model with 1.5B parameters.
	  48 layers, 25 heads, 1600 embedding dimension.
	  WARNING: Requires 128+ GB system RAM for loading!
	  GPU Memory: ~24-40 GB for training

endchoice

config GPT2_MODEL_NAME
	string
	default "gpt2" if GPT2_MODEL_124M
	default "gpt2-medium" if GPT2_MODEL_350M
	default "gpt2-large" if GPT2_MODEL_774M
	default "gpt2-xl" if GPT2_MODEL_1558M

# Dataset selection
choice
	prompt "Training Dataset"
	default GPT2_DATASET_SHAKESPEARE
	help
	  Select the dataset to use for training GPT-2.

config GPT2_DATASET_SHAKESPEARE
	bool "Shakespeare (tiny)"
	help
	  Tiny Shakespeare dataset (~1MB of text).
	  Good for testing and development.
	  ~300K training tokens, ~36K validation tokens.

config GPT2_DATASET_FINEWEBEDU
	bool "FineWebEdu"
	help
	  FineWebEdu dataset - educational web content.
	  High-quality filtered educational text.
	  Requires downloading and preprocessing.

config GPT2_DATASET_OPENWEBTEXT
	bool "OpenWebText"
	help
	  OpenWebText dataset - replication of GPT-2's WebText.
	  Large-scale web scrape dataset.
	  Requires significant storage and preprocessing.

config GPT2_DATASET_CUSTOM
	bool "Custom dataset"
	help
	  Use a custom dataset.
	  Specify path to preprocessed .bin files.

endchoice

config GPT2_DATASET_NAME
	string
	default "shakespeare" if GPT2_DATASET_SHAKESPEARE
	default "finewebedu" if GPT2_DATASET_FINEWEBEDU
	default "openwebtext" if GPT2_DATASET_OPENWEBTEXT
	default "custom" if GPT2_DATASET_CUSTOM

config GPT2_CUSTOM_DATASET_PATH
	string "Custom dataset path"
	depends on GPT2_DATASET_CUSTOM
	default "data/custom"
	help
	  Path to directory containing train.bin and val.bin files.

# Training hyperparameters
config GPT2_BLOCK_SIZE
	int "Context length (block size)"
	default 1024
	range 128 2048
	help
	  Maximum sequence length for training.
	  Must be less than or equal to model's maximum (1024 for GPT-2).

config GPT2_GRADIENT_ACCUMULATION
	int "Gradient accumulation steps"
	default 1
	range 1 128
	help
	  Number of gradient accumulation steps.
	  Effective batch size = batch_size * gradient_accumulation_steps.
	  Use higher values to simulate larger batch sizes on limited GPU memory.

config GPT2_EVAL_INTERVAL
	int "Evaluation interval (steps)"
	default 100
	range 10 10000
	help
	  Evaluate model every N training steps.

config GPT2_EVAL_SAMPLES
	int "Evaluation samples"
	default 200
	range 10 10000
	help
	  Number of samples to use for evaluation.

config GPT2_WARMUP_STEPS
	int "Learning rate warmup steps"
	default 100
	range 0 10000
	help
	  Number of warmup steps for learning rate schedule.
	  0 disables warmup.

config GPT2_DECAY_LR
	bool "Enable learning rate decay"
	default y
	help
	  Use cosine learning rate decay schedule.

config GPT2_MIN_LR
	string "Minimum learning rate"
	default "6e-5"
	depends on GPT2_DECAY_LR
	help
	  Minimum learning rate for cosine decay.
	  Typically 1/10th of max learning rate.

# Generation settings
config GPT2_GENERATION_TEMPERATURE
	string "Generation temperature"
	default "0.8"
	help
	  Temperature for text generation sampling.
	  Lower values (0.5) = more focused/deterministic.
	  Higher values (1.0) = more diverse/random.

config GPT2_GENERATION_TOP_K
	int "Top-k sampling"
	default 200
	range 0 50000
	help
	  Only sample from top k tokens.
	  0 = no restriction (sample from all tokens).

config GPT2_GENERATION_MAX_TOKENS
	int "Maximum generation length"
	default 500
	range 10 10000
	help
	  Maximum number of tokens to generate.

# Advanced options
config GPT2_FLASH_ATTENTION
	bool "Use Flash Attention"
	default y
	help
	  Use Flash Attention for faster training (requires PyTorch >= 2.0).
	  Significantly reduces memory usage and increases speed.

config GPT2_COMPILE
	bool "Compile model with torch.compile()"
	default y
	depends on COMPILE_MODEL
	help
	  Use torch.compile() for faster execution.
	  Requires PyTorch >= 2.0.

config GPT2_WEIGHT_TYING
	bool "Use weight tying"
	default y
	help
	  Share weights between input embedding and output projection.
	  Standard practice for GPT models.

config GPT2_DROPOUT
	string "Dropout rate"
	default "0.1"
	help
	  Dropout rate for regularization.
	  0.0 = no dropout, 0.1 = 10% dropout.

config GPT2_BIAS
	bool "Use bias in Linear/LayerNorm"
	default y
	help
	  Whether to use bias terms in Linear and LayerNorm layers.
	  GPT-2 uses bias, but newer models often don't.

# Distributed Training
config GPT2_USE_DDP
	bool "Enable Distributed Data Parallel (DDP)"
	default n
	help
	  Enable multi-GPU training with PyTorch Distributed Data Parallel.
	  This allows training across multiple GPUs on one or more nodes.
	  Recommended for systems with multiple GPUs like H100x8.

config GPT2_DDP_BACKEND
	string "DDP backend"
	default "nccl"
	depends on GPT2_USE_DDP
	help
	  Backend for distributed training.
	  - nccl: NVIDIA GPUs (recommended)
	  - gloo: CPU or mixed environments
	  - mpi: MPI-based clusters

config GPT2_DDP_FIND_UNUSED_PARAMS
	bool "Find unused parameters in DDP"
	default y
	depends on GPT2_USE_DDP
	help
	  Enable finding unused parameters in the model.
	  Required for models with conditional execution paths.
	  May add slight overhead but ensures correctness.

config GPT2_DDP_NUM_GPUS
	int "Number of GPUs for DDP"
	default 1
	range 1 16
	depends on GPT2_USE_DDP
	help
	  Number of GPUs to use for distributed training.
	  This overrides PARALLEL_JOBS when DDP is enabled.
	  Set to 8 for H100x8 systems.

# AdamWPrune State Pruning Variants (Bitter Lesson)
config GPT2_ADAMWPRUNE_VARIANT_BITTER0
	bool "Enable bitter0 variant (original hybrid approach)"
	default y
	help
	  Original AdamWPrune state-based pruning using momentum-stability scoring.
	  Combines Adam momentum and stability signals for pruning decisions.
	  Result: 51.39 perplexity, 49.7% sparsity, 478.8 min training time.

config GPT2_ADAMWPRUNE_VARIANT_BITTER1
	bool "Enable bitter1 variant (pure magnitude)"
	default n
	help
	  Pure magnitude pruning with boolean masks for memory efficiency.
	  Simple approach following the bitter lesson - magnitude scoring works.
	  Expected: ~42 perplexity (similar to AdamWSPAM+magnitude), faster training.

config GPT2_ADAMWPRUNE_VARIANT_BITTER2
	bool "Enable bitter2 variant (scale-aware magnitude)"
	default n
	help
	  Magnitude pruning that signals to use saved resources:
	  - 21% more iterations (12,100 instead of 10,000)
	  - OR 14% larger batch size
	  Let scale improvements compensate for simplicity.

config GPT2_ADAMWPRUNE_VARIANT_BITTER3
	bool "Enable bitter3 variant (gradient-magnitude)"
	default n
	help
	  Gradient-magnitude pruning: |w| * sqrt(|grad_avg|)
	  Uses gradient information with cubic sparsity schedule.
	  Extended to 13000 iterations (+30%) for better quality.
	  Expected: ~42-44 perplexity, improvement over bitter2.

config GPT2_ADAMWPRUNE_VARIANT_BITTER4
	bool "Enable bitter4 variant (gradient-magnitude + layer-adaptive)"
	default n
	help
	  Gradient-magnitude with layer-adaptive sparsity distribution.
	  Early layers: 0.7x sparsity, later layers: 1.3x sparsity.
	  Extended to 13000 iterations (+30%) with cubic schedule.
	  Expected: ~40-42 perplexity, best performance.

config GPT2_ADAMWPRUNE_DEFAULT_VARIANT
	string "Default AdamWPrune variant"
	default "bitter0"
	help
	  Default variant to use when not specified in command line.
	  Options: bitter0 (original), bitter1 (magnitude), bitter2 (scale-aware).

endmenu

