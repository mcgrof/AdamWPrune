#
# GPT-2 Configuration for testing fixed issues
# Tests the movement pruning frequency fix and AdamWPrune state pruning fix
# Only runs 2 specific combinations that had issues:
#   1. AdamWSPAM + movement pruning @ 50% (was overshooting to 73%)
#   2. AdamWPrune + state pruning @ 50% (was crashing with TypeError)
#

# Model Selection - GPT-2
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_GPT2=y
CONFIG_MODEL="gpt2"
CONFIG_TEST_MODELS="gpt2"
CONFIG_GPT2_MODEL_SIZE="124M"
# Enable model compilation
CONFIG_COMPILE_MODEL=y

# Enable test matrix mode
CONFIG_TEST_MATRIX_MODE=y

# Optimizer Configuration - Test AdamWSPAM and AdamWPrune
CONFIG_OPTIMIZER_MODE_MULTIPLE=y
CONFIG_OPTIMIZER_ENABLE_ADAMWSPAM=y
CONFIG_OPTIMIZER_ENABLE_ADAMWPRUNE=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWSPAM=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWPRUNE=y
# Disable all other optimizers
CONFIG_OPTIMIZER_ENABLE_SGD=n
CONFIG_OPTIMIZER_ENABLE_ADAM=n
CONFIG_OPTIMIZER_ENABLE_ADAMW=n
CONFIG_OPTIMIZER_ENABLE_ADAMWADV=n

# AdamWPrune specific settings
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_TARGET_SPARSITY="0.5"
CONFIG_ADAMWPRUNE_FREQUENCY=50
CONFIG_ADAMWPRUNE_WARMUP_STEPS=100
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.95"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.1"
CONFIG_ADAMWPRUNE_AMSGRAD=n

# SPAM settings (used by both AdamWSPAM and AdamWPrune)
CONFIG_SPAM_ENABLE_CLIP=y
CONFIG_SPAM_SPIKE_THRESHOLD="2.0"
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_WARMUP=y
CONFIG_SPAM_WARMUP_STEPS=1000
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_PERIODIC_RESET=y

# Pruning Configuration - Only test movement and state
CONFIG_PRUNING_MODE_MULTIPLE=y
CONFIG_PRUNING_ENABLE_MAGNITUDE=n
CONFIG_PRUNING_ENABLE_MOVEMENT=y
CONFIG_PRUNING_ENABLE_STATE=y
CONFIG_PRUNING_ENABLE_NONE=n
CONFIG_PRUNING_ENABLED_MOVEMENT=y
CONFIG_PRUNING_ENABLED_STATE=y
CONFIG_TEST_PRUNING_MAGNITUDE=n
CONFIG_TEST_PRUNING_MOVEMENT=y
CONFIG_TEST_PRUNING_NONE=n
CONFIG_TEST_PRUNING_METHODS="movement"

# Pruning warmup
CONFIG_PRUNING_WARMUP=100

# Only test 50% sparsity
CONFIG_TARGET_SPARSITY="0.5"
CONFIG_SPARSITY_ENABLE_50=y
CONFIG_SPARSITY_ENABLE_70=n
CONFIG_SPARSITY_ENABLE_90=n
CONFIG_SPARSITY_ENABLE_95=n
CONFIG_SPARSITY_ENABLE_99=n
CONFIG_TEST_SPARSITY_50=y
CONFIG_TEST_SPARSITY_70=n
CONFIG_TEST_SPARSITY_90=n

# Single-GPU Configuration
# CONFIG_GPT2_USE_DDP is not set
CONFIG_GPT2_DDP_NUM_GPUS=1
CONFIG_GPT2_DDP_BACKEND="nccl"
CONFIG_GPT2_DDP_FIND_UNUSED_PARAMS=n

# Training Parameters
CONFIG_BATCH_SIZE=32
CONFIG_GPT2_GRADIENT_ACCUMULATION=4
CONFIG_NUM_EPOCHS=10
CONFIG_GPT2_MAX_ITERS=10000
CONFIG_GPT2_EVAL_INTERVAL=500
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_LOG_INTERVAL=10

# Learning Rate Schedule
CONFIG_LEARNING_RATE="6e-4"
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y

# Dataset Configuration
CONFIG_DATA_DIR="./gpt2/data"
CONFIG_GPT2_DATASET_FINEWEBEDU=y
CONFIG_GPT2_DATASET="finewebedu"
CONFIG_GPT2_BLOCK_SIZE=1024

# Data Loading Optimization
CONFIG_NUM_WORKERS=16
CONFIG_PIN_MEMORY=y
CONFIG_PERSISTENT_WORKERS=y
CONFIG_PREFETCH_FACTOR=4

# Mixed Precision Training
CONFIG_MIXED_PRECISION=y
CONFIG_GPT2_AMP_DTYPE="bfloat16"

# Performance Optimizations
CONFIG_GPT2_CUDNN_BENCHMARK=y
CONFIG_GPT2_TF32_ALLOWED=y
CONFIG_GPU_WARMUP=y

# Memory Optimizations
CONFIG_PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# Checkpointing
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
CONFIG_OUTPUT_DIR="./results/adamwspam-movement-vs-adamwprune-50"

# Experiment Tracking
CONFIG_GPT2_TRACKER="wandb,trackio"
CONFIG_TRACKER_PROJECT="tracking-e97b5"

# Test execution
CONFIG_TEST_PARALLEL_JOBS=1
