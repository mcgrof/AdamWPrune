# GPT-2 on Shakespeare dataset - Conservative settings for limited system RAM
# Safe for systems with 16GB system RAM
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_GPT2=y
CONFIG_MODEL_GPT2=y
CONFIG_MODEL="gpt2"

# GPT-2 Configuration
CONFIG_GPT2_MODEL_124M=y
CONFIG_GPT2_MODEL_NAME="gpt2"
CONFIG_GPT2_DATASET_SHAKESPEARE=y
CONFIG_GPT2_DATASET_NAME="shakespeare"
CONFIG_GPT2_BLOCK_SIZE=256
CONFIG_GPT2_GRADIENT_ACCUMULATION=2
CONFIG_GPT2_EVAL_INTERVAL=100
CONFIG_GPT2_EVAL_SAMPLES=100  # Reduced eval samples
CONFIG_GPT2_WARMUP_STEPS=100
CONFIG_GPT2_DECAY_LR=y
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_DROPOUT="0.1"
CONFIG_GPT2_FLASH_ATTENTION=y
CONFIG_GPT2_COMPILE=y
CONFIG_GPT2_WEIGHT_TYING=y
CONFIG_GPT2_BIAS=y

# Conservative training parameters
CONFIG_BATCH_SIZE=32  # Smaller batch to reduce memory pressure
CONFIG_NUM_EPOCHS=1
CONFIG_LEARNING_RATE="6e-4"
CONFIG_WEIGHT_DECAY="0.1"
CONFIG_NUM_WORKERS=2  # Minimal workers to save RAM
CONFIG_DEVICE="cuda"

# Optimizer - AdamW
CONFIG_OPTIMIZER_MODE_SINGLE=y
CONFIG_OPTIMIZER_SELECT_ADAMW=y
CONFIG_OPTIMIZER="adamw"

# No pruning
CONFIG_PRUNING_MODE_NONE=y

# Advanced options
CONFIG_COMPILE_MODEL=y
CONFIG_MIXED_PRECISION=y
CONFIG_GPU_WARMUP=y
CONFIG_SAVE_CHECKPOINT=y
